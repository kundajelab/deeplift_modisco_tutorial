{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from simdna import synthetic as sn\n",
    "import avutils\n",
    "from avutils import file_processing as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the simulation (number per type of sequence, the three tasks, the different motifs, ENCODE images of the motifs, and also the GC content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the testing set of our model for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = sn.read_simdata_file(\"sequences.simdata.gz\", ids_to_load=fp.read_rows_into_arr(\"splits/test.txt.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the contents of the raw_data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can access the raw underlying sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTTGTATTGAGTTAGAAACCGCCACGGCACTGCTATGTATGACATTCTAACTAAGTGAGTTATGCGTTGGGTCCTTTATGTGGCATTATCTGGTAATACTTAATTGATGTACTATTTCCTCGACAAAACAGGTGGTGTGGGTGTACCGGTCACCGATAAGGGGGAACTCACCAGATGGTAGTTAACCTATAGAGTCCTGA',\n",
       " 'TGACAATGGACCCGGTCCGGGTTAGGTACTGATTAGGAACGACCCAGGCCGAGCGACTTATCCCGTTAGATGACGGAATCGTTGTTAGCGGAAAAGAGATAAGAACTTCCCAATTTATACAGATAAGCACACAATGTTTAACGTTCCCGTCTGAGTACTCCTGAATGGGAAGGATATTCTATACTAAGGGATTAGTCGTG',\n",
       " 'CGTTTGAAAGGAGACCAGGTGGTCCAACCACAGTAGCAGAATATTATGCGGTTGTCGATAGAGCTTTGCTAACAGATGTTTACAGTTATCCTGAAATCGTTTGGACAAACTGTCTTCGTGCGTAATTGCACTGTTATGGCCCAGTACAGGGGATCAGATGGTCATGGCAAAAGGCGTGCCAACGCTCGAACTGGAGTCTT',\n",
       " 'TATGACGACTGCGTATAGTAGACAGATGGTGGACAATTCCCCGTTACATAAAGGGGTACAGATGGTAAGTCCACAAACCGTAACGGCAACAGATGTTTTGAGGTACAAATATAAGGTCCTGATAAGGAGCCGAGAGCTGACGCGTGCCCAATGAGTACATACGTGATACGAATGCGTGCGCCCGGAGTATGTCAAACCGT',\n",
       " 'CAGTATCTACTGAAAGGAGAATGCACTTGCCGCAATTAACATCCTCTGATTGCACTTGAGTATTTAACAATATATTATGAGCAAGACGCCGGCCTTGTAAAAGACCAAATATAAGGACAATCTAGGGGCGCGTGACCAAGACTGCATCATATCTTCCAAATTTAGTAGTACGCCGTGGAGCGTGATGCGAGTGCTCCACG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...As well as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the actual contents of the motif objects that were embedded in the original simulation. Can you verify the relationship between the labels and the embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos-151_GATA_disc1-ACCGATAAGG, pos-123_TAL1_known1-CAAAACAGGTGGTGTG, pos-166_TAL1_known1-CTCACCAGATGGTAGT\n",
      "pos-94_GATA_disc1-AGAGATAAGA, pos-118_GATA_disc1-ACAGATAAGC, pos-27_GATA_disc1-ACTGATTAGG\n",
      "pos-149_TAL1_known1-GGGATCAGATGGTCAT, pos-67_TAL1_known1-GCTAACAGATGTTTAC, pos-10_TAL1_known1-GAGACCAGGTGGTCCA\n",
      "pos-161_GATA_disc1-CGTGATACGA, pos-117_GATA_disc1-CCTGATAAGG, pos-84_TAL1_known1-GGCAACAGATGTTTTG, pos-53_TAL1_known1-GGGTACAGATGGTAAG, pos-17_TAL1_known1-GTAGACAGATGGTGGA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\", \".join(str(embedding) for embedding in embeddings_one_seq)\n",
    "                     for embeddings_one_seq in raw_data.embeddings[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have to one-hot encode the data, so let's do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_data = avutils.util.one_hot_encode_sequences(raw_data.sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a DeepLIFT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now set up a DeepLIFT model. In this tutorial, we will start with a keras model and use the deeplift autoconversion functions to create a DeepLIFT model. Note that it is not necessary to have a keras model; if you have a model trained with a different package, you can write your own conversion scripts to put it in the DeepLIFT format - information on how to do so is documented on the DeepLIFT repo https://github.com/kundajelab/deeplift#under-the-hood. For now, we will stick to the autoconversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with loading a keras model. We're going to load a Keras graph model (version 0.3.2). When we load the model, we need to specify the weights and the configuration (the weights are stored in the .h5 format and the configuration is stored in the .yaml format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import deeplift.conversion.keras_conversion as kc\n",
    "\n",
    "keras_model_weights = \"model_files/record_1_model_9vvXe_modelWeights.h5\"\n",
    "keras_model_yaml = \"model_files/record_1_model_9vvXe_modelYaml.yaml\"\n",
    "\n",
    "keras_model = kc.load_keras_model(weights=keras_model_weights, yaml=keras_model_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the Keras model to the DeepLIFT format using the provided autoconverion functions. When we convert the model, we need to specify a reference to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deeplift_model = kc.convert_graph_model(model=keras_model,\n",
    "                    nonlinear_mxts_mode=nonlinear_mxts_mode,\n",
    "                    dense_mxts_mode=dense_mxts_mode,\n",
    "                    reference=reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
